{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cd03a5-bcf4-4764-8ab5-03c4f3ca0129",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "- **Context and Company Background:** TechWorks Consulting, a company specializing in IT talent recruitment, and highlights its unique approach to matching skilled IT professionals with job opportunities.\n",
    "- **Data Description:** The Dataset conatins information about colleges, cities, roles, previous experience, and salary. This information will be used to train and test the predictive model.\n",
    "- **Regression Task:** The primary objective is to perform a regression task, where the aim is to predict a continuous variable, specifically the salary of newly hired employees.\n",
    "- **Role of Statistics:** The role of statistics is to build and check the accuracy of the model.\n",
    "- **Data Preprocessing:** Data Preprocessing is most important task as it involves tasks like handling missing values, outliers, categorical variables, normalization, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be447d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078ea130-b933-4a19-9739-9dd5c94414d9",
   "metadata": {},
   "source": [
    "# Creating a Salary Prediction Model: A Systematic Approach\n",
    "- **Data Understanding:**\n",
    "  - Begin by thoroughly understanding the provided dataset, including its structure, columns, and the meaning of each variable. Gain insights into the data's distribution, summary statistics, and potential outliers.\n",
    "- **Data Preprocessing:**\n",
    "  - Handle Missing Values: Identify and address missing data by imputation or removal, ensuring that data is complete.\n",
    "  - Outlier Detection and Treatment: Detect and handle outliers in the dataset, which could impact the model's accuracy.\n",
    "  - Convert Categorical Data: Transform categorical variables (e.g., \"College\" and \"City\") into numerical format.\n",
    "  - Normalize Data: Normalize numerical features to bring them to a common scale to avoid any feature dominating the model.\n",
    "  - Feature Selection: Use statistical techniques such as Lasso, Ridge, or correlation analysis to select the most relevant features for salary prediction.\n",
    "    - **Performing Exploratory Data Analysis (EDA)**\n",
    "    - **Model Selection:**\n",
    "        - Choose different regression models (e.g., Linear Regression, Multi Linear Regression) to build and evaluate the predictive models.\n",
    "    - **Model Training and Evaluation:**\n",
    "        - Split the dataset into training and testing sets to train the models and assess their performance.\n",
    "        - Use appropriate evaluation metrics like Mean Squared Error (MSE), R-squared, and Mean Absolute Error (MAE) to measure the model's accuracy.\n",
    "        - Experiment with different hyperparameters for each model and use cross-validation to avoid overfitting.\n",
    "    - **Model Comparison:**\n",
    "        - Compare the performance of different models and select the one with the best accuracy and generalization.\n",
    "    - **Further Improvement:**\n",
    "        - Consider additional techniques for model improvement, such as feature engineering, hyperparameter tuning, and ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c9911-1407-470b-b7c3-02cd39d12ef5",
   "metadata": {},
   "source": [
    "# The available ML model options had to perform on this task\n",
    "#### In the task of predicting employee salary at TechWorks Consulting, there are several machine learning model options available for regression tasks. The choice of the model depends on various factors, including the nature of the data, the complexity of the problem, and the need for model interpretability. Here are some of the available ML model options:\n",
    "**1. Linear Regression:**\n",
    "- Linear regression is a simple and interpretable model that assumes a linear relationship between the features and the target variable (salary). It's a good starting point and can provide baseline performance.\n",
    "\n",
    "**2. Ridge Regression and Lasso Regression:**\n",
    "- Ridge and Lasso regression are regularization techniques that can be used to handle multicollinearity and prevent overfitting. They are variants of linear regression that add regularization terms to the cost function.\n",
    "\n",
    "**3. Decision Trees:**\n",
    "- Decision tree-based models, like Random Forest and Gradient Boosting, are capable of capturing non-linear relationships in the data. They can handle both numerical and categorical features and automatically deal with feature importance.\n",
    "\n",
    "**4. K-Nearest Neighbors (KNN):**\n",
    "- KNN is a non-parametric method that makes predictions based on the average of the 'k' nearest data points. It can be effective for small to medium-sized datasets.\n",
    "\n",
    "**5. Polynomial Regression:**\n",
    "- Polynomial regression can be used to capture non-linear relationships by introducing polynomial features.\n",
    "\n",
    "I will be performing 3 of them with default parameters and with somes doing changes in parameter to showcase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40404809-4398-4bfd-96be-11c674cfa537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and analysis\n",
    "# Import the numpy library for numerical operations and array processing\n",
    "# Import the seaborn library for data visualization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec1f61-3006-4fa5-a58d-9452bb32f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file into a DataFrame\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/Preet/ML-PROJECT/data/ML case Study.csv\")\n",
    "college = pd.read_csv(\"C:/Users/Preet/ML-PROJECT/data/Colleges.csv\")\n",
    "cities = pd.read_csv(\"C:/Users/Preet/ML-PROJECT/data/cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe30ad2-26f1-455e-bc53-f57de76fa20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of Data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc9788-c8c6-4437-afbf-b58f4ccfd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of College data\n",
    "\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dec59-5df6-4b24-b264-09d2ff078873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of City data\n",
    "\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f781d-78f6-47f0-902b-629bc74fae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the \"Tier 1,\" \"Tier 2,\" and \"Tier 3\" columns of the 'college' DataFrame\n",
    "# and store them in separate lists 'Tier1,' 'Tier2,' and 'Tier3' for further analysis.\n",
    "\n",
    "Tier1 = college[\"Tier 1\"].tolist()\n",
    "Tier2 = college[\"Tier 2\"].tolist()\n",
    "Tier3 = college[\"Tier 3\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc4da0-c758-41e8-b80e-f52ad0fc6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing data contains in Tier1\n",
    "\n",
    "Tier1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76e129-f8b7-4038-8e44-efa04a98a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tier values to colleges in the DataFrame based on their tier classification\n",
    "# - If a college is in 'Tier1', set its value to 3\n",
    "# - If a college is in 'Tier2', set its value to 2\n",
    "# - If a college is in 'Tier3', set its value to 1\n",
    "# Tier1 college get value of 3 and tier 3 of 1 because tier1 college has higher weightage then 2 and 3.\n",
    "\n",
    "for item in df.College:\n",
    "    if item in Tier1:\n",
    "        df[\"College\"].replace(item,3,inplace=True)\n",
    "    elif item in Tier2:\n",
    "        df[\"College\"].replace(item,2,inplace=True)\n",
    "    elif item in Tier3:\n",
    "        df[\"College\"].replace(item,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603099b-efdf-47dc-b06b-2f8fd6a142e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b89344-fb02-4696-a05c-ff74c17c9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting lists of metropolitan and non-metropolitan cities from the 'cities' DataFrame\n",
    "\n",
    "metro = cities['Metrio City'].tolist()\n",
    "non_metro_cities = cities['non-metro cities'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b6333-98dc-4731-a3ee-bfc6395a7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for item in df.City:\n",
    "    if item in metro:\n",
    "        df['City'].replace(item,1,inplace=True)\n",
    "    elif item in non_metro_cities:\n",
    "        df['City'].replace(item,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b774af3-a310-4e1f-8ef4-f0bc90c3f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f295d9-fd78-4789-9388-5f04deb4b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4723e3-9fda-4d2c-89e8-fbecff2ece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93856f96-692b-4a3f-9f3e-03bccedacb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values in data\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ed583-d79b-4275-a936-76fcac42f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22bd27-f281-4594-a836-4745f9474de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical info about numerical data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d48041-151e-4257-beec-5d6ca099dbde",
   "metadata": {},
   "source": [
    "# Detection of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c7ab7-1de5-43b7-b915-418d15a2c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using seaborn library to plot box plot for detection of outliers\n",
    "sns.boxplot(df['Previous CTC'])\n",
    "plt.savefig('plots/previous_ctc_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfeda7b-af76-401a-8db7-47b1f04ef7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['Graduation Marks'])\n",
    "plt.savefig('plots/graduation_marks_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e57a2e-353e-4e4c-849e-c77a5e1616c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['EXP (Month)'])\n",
    "plt.savefig('plots/exp_month_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563efeb7-dcd1-4eda-94c6-eed50f85deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df['CTC'])\n",
    "plt.savefig('plots/ctc_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b622c7f-4e60-48d9-be94-f203485440de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corelation between variables\n",
    "corr = df.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f424a85-f81d-4998-8439-601aee043227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual representation of corr\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.savefig('plots/correlation_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6addd35-d54e-4c67-a7c8-1fb336344547",
   "metadata": {},
   "source": [
    "#### Outliers present in Previous CTC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9003bf-cdad-4a89-8c3a-45a2ee434b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent25 = df['Previous CTC'].quantile(0.25)\n",
    "percent75 = df['Previous CTC'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a59bf2-4b08-4933-b4e8-fe0438605f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = percent75-percent25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6b4f4-adff-4b5f-aee7-200c7ee66d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = percent75 + 1.5*iqr\n",
    "lower_limit = percent25 - 1.5*iqr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceedcce6-b862-435e-aa43-735ce12ace93",
   "metadata": {},
   "source": [
    "df[(df['Previous CTC'] < lower_limit) | (df['Previous CTC'] > upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d90849-ec1c-4dd6-9de7-c7bbc927d78c",
   "metadata": {},
   "source": [
    "In the above DataFrame, These are outliers present in \"Previous CTC\"column. As seen these outliers are not extreme, so in my opinion keeping these data may not affect much on my model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9c108-610d-4711-bc64-c8cfe74aa234",
   "metadata": {},
   "source": [
    "#### Outliers present in CTC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9537c273-75d0-471c-b670-6cbdbf1ffcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent25 = df['CTC'].quantile(0.25)\n",
    "percent75 = df['CTC'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d328b9-1fc0-4884-a2f8-caa0c908cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr = percent75-percent25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e184d-c6a8-4ebd-81a3-8b9f25a01e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = percent75 + 1.5*iqr\n",
    "lower_limit = percent25 - 1.5*iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed531b1-c2f0-43d4-aebc-92df7737a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['CTC'] < lower_limit) | (df['CTC'] > upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da049084-296c-4aed-a83b-66a4b972f329",
   "metadata": {},
   "source": [
    "As seen above, these are some outliers in \"CTC\" column but they are not as extreme that can make any huge difference while making prediction. Therefore in my opinion keeping those outliers into data is more useful than removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a4cb0-e253-4ab1-ade8-a4c1bda490ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c4f6ae8-677b-4b14-8f7a-97d9c7e21d01",
   "metadata": {},
   "source": [
    "### Conclusion on detection of Outliers:\n",
    "- There were as such no extreme outliers present in our dataset that can make any huge difference in machine learning model. Also from describe function it is clear that there is no extreme outliers.\n",
    "- As seen above in \"Previous CTC\" and \"CTC\", there are some outliers but from my perspective these are not going to affect my model.\n",
    "- In the HeatMap figure, there are some relation between Role_manager and CTC and Previous CTC and CTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d1412-f8ce-462a-b169-4f976d32aa97",
   "metadata": {},
   "source": [
    "# Applying Machine Learning models without Feature Scaling\n",
    "Considering all possible algorithm without any scaling to check performance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bce0e-aad0-430f-9149-990aa59f25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data splitting, modeling, and evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad42aa0-b159-4ecb-93ae-7a612211ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and Independent Variable\n",
    "\n",
    "X = df.loc[:, df.columns != 'CTC']\n",
    "y = df['CTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92732a8-42d2-425a-a03d-d968cdc25931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into train and test with test_size = 0.2(80% data into train and 20% to test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ada1a-a432-412f-bc56-3d3460408847",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc7277-d015-4e4b-a413-d082515cee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "linear_reg_pred = linear_reg.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, linear_reg_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",linear_reg.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",linear_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764760ef-ac83-4076-ad77-e788e4942e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Ridge regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Fit the model to training data\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "ridge_predict = ridge.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_predict))\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",ridge.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",ridge.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755cf089-71e2-409e-8510-18be12f1058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Ridge regression model with a specified alpha value and solver\n",
    "ridge_tuned = Ridge(alpha=0.3, solver='cholesky')\n",
    "\n",
    "# Fit the Ridge model to the training data\n",
    "ridge_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the tuned Ridge model\n",
    "ridge_predict_tuned = ridge.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, ridge_predict_tuned))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) to evaluate model performance\n",
    "print(\"MAE:\",mean_absolute_error(y_test, ridge_predict_tuned))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate model performance\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_predict_tuned))\n",
    "\n",
    "print()\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",ridge_tuned.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",ridge_tuned.intercept_)"
   ]
  }
 ]
}